#Removal using NLTK
import nltk
from nltk.corpus import stopwords
sw_nltk = stopwords.words('english')
text = "When I first met her she was very quiet. She remained quiet during the entire two hour long journey from Stony Brook to New York."
words = [word for word in text.split() if word.lower() not in sw_nltk]
new_text = " ".join(words)
#Add your custom stop words
sw_nltk.extend(['first', 'second', 'third', 'me'])
print(len(sw_nltk))
#Remove stop words from the original list
sw_nltk.remove('not')

#Removal using Spacy
import spacy
#loading the english language small model of spacy
en = spacy.load('en_core_web_sm')
sw_spacy = en.Defaults.stop_words
words = [word for word in text.split() if word.lower() not in sw_spacy]
new_text = " ".join(words)

#Removal using Gensim
import gensim
from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS
new_text = remove_stopwords(text)

#Removal using Scikit-learn
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
words = [word for word in text.split() if word.lower() not in ENGLISH_STOP_WORDS]
new_text = " ".join(words)

#Create your custom stop words list
my_stop_words = ['her','me','i','she','it']
words = [word for word in text.split() if word.lower() not in my_stop_words]
new_text = " ".join(words)


