from mlxtend.classifier import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC, LinearSVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn import model_selection
from sklearn.metrics import confusion_matrix, classification_report, make_scorer
from sklearn.metrics import accuracy_score, recall_score, precision_recall_curve
from sklearn.model_selection import StratifiedKFold, cross_validate

lgbm_cl = LGBMClassifier(random_state=seed)
rf_cl = RandomForestClassifier(10, random_state=seed)
knn_cl = KNeighborsClassifier()
logreg = LogisticRegression()

sclf = StackingClassifier(classifiers=[lgbm_cl, rf_cl,knn_cl],
                          meta_classifier=logreg)

label = ['LGBM', 'Random Forest','KNN' 'Stacking Classifier']
clf_list = [lgbm_cl, rf_cl,knn_cl, logreg]

for clf, label in zip([lgbm_cl, rf_cl,knn_cl,sclf], 
                      ['LGBM', 
                       'Random Forest', 
                       'KNN',
                       'StackingClassifier']):
#X and y contain the input and output respectively
    scores = model_selection.cross_val_score(clf, X, y, 
                                              cv=3, scoring='accuracy')
    print("Accuracy: %0.2f (+/- %0.2f) [%s]" 
          % (scores.mean(), scores.std(), label))